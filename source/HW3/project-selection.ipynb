{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-68fbe74720155561",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<center>\n",
    "<div class=\"h1\">Info 114: Introduction to Data Science</div>\n",
    "<div class=\"h1\">Homework 3: from VI-ME-BA-BAR to POM</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8e378565cf037385",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Part 3: Project selection\n",
    "You will find below some code that was written to prepare the class.\n",
    "We will go more in depth over these questions in later classes.\n",
    "This is a \"preview\" to help you select your project.\n",
    "\n",
    "Our problem seems rather complex. Non-linear methods perform best.\n",
    "Unfortunately, these methods are hard to understand.\n",
    "To make progress, we must try to visualize our data again.\n",
    "\n",
    "In this worksheet, we use as example the data of `CS_data.csv`, after standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e215bd81c577716",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Setup: import code an load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e3f0a32efa9f989d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "from glob import glob as ls\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "from PIL import Image\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cb730cecaf7c0930",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "code_dir = './code'\n",
    "from sys import path; path.append(code_dir); \n",
    "from utilities import *\n",
    "from my_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6b468c0061a5820f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data_dir = './mini-dataset/'\n",
    "data_df = standardize_df(pd.read_csv(data_dir + 'CS_data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a9066373f9638d61",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4d61d2ca9cb09366",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Since it is very important to visualize data, we show below a heatmap of the data in which the lignes and columns have been re-arranged according to their resemblance. This is an \"unsupervised learning\" visualization method, so we omit the last column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_df.iloc[:, :-1]\n",
    "heatmap(df, 'average', 'single', 'euclidean', 'euclidean', 'coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, we show what happens if we randomize completely the order of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = shuffle(df)\n",
    "heatmap(df2, 'average', 'single', 'euclidean', 'euclidean', 'coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "\n",
    "\n",
    "We display the correlation matrix of `data_df`, following <a href=\"https://stackoverflow.com/questions/29432629/plot-correlation-matrix-using-pandas\">this page</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data_df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the hierarchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(corr, 'average', 'average', 'euclidean', 'euclidean', 'coolwarm', default_window_hight = 15, default_window_width = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look for the most correlated or anti-correlated feature/variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(corr.values, 0)\n",
    "print('Most correlated: ' + corr.fruit.argmax())\n",
    "print('Most anti-correlated: ' + corr.fruit.argmin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you surprised? I was surprised. In the first toy dataset we played with, apples were correlated with red. This is no longer the case. You can check out the dataset and understand why. In this new dataset, most apples are gree. Many bananas are yellow and some are green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_image(data_dir + 'all_data.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is not completely well balanced, so the Pearson correlation coefficient may not be the best way to identify the most informative features. Let's see whether S2N makes a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s2n_coeff = s2n(data_df)\n",
    "print('Largest s2n: ' + s2n_coeff.feat.argmax())\n",
    "print('Smallest s2n: ' + s2n_coeff.feat.argmin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the same features with S2N and the Pearson correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "We are going to perform some simple-minded feature selection with the Pearson correlation coefficient. This will allow us to do some data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first sort all features by the absolute value of the Pearson correlation coefficient. Indeed, variables are informative no matter whether they are correlated or anti-correlated (since it suffices to multiply them by -1 to change the correlation direction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by correlation coefficient\n",
    "sval = corr['fruit'][:-1].abs().sort_values(ascending=False)\n",
    "ranked_columns = sval.index.values\n",
    "print(ranked_columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the features that we had constructed in previous lessons 'R-(G+B)/2' and 'W/H' come in the 5 top most informative features. But there are others. Let us make all scatter plots of pairs of features for the 5 top ranked features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_name = ['Banana', 'Apple']\n",
    "fruit_list = [fruit_name[int((i+1)/2)] for i in data_df[\"fruit\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_selected = ranked_columns[0:5]\n",
    "df_new = pd.DataFrame.copy(data_df)\n",
    "df_new = df_new[col_selected]\n",
    "df_new['fruit'] = fruit_list\n",
    "g = sns.pairplot(df_new, hue=\"fruit\", markers=[\"o\", \"s\"], diag_kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to see how many features are needed to obtain nearly as good performance as with all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score as sklearn_metric\n",
    "sklearn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "feat_lc_df = feature_learning_curve(data_df, sklearn_model, sklearn_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_lc_df[['perf_tr', 'perf_te']].plot()\n",
    "plt.errorbar(feat_lc_df.index+1, feat_lc_df['perf_tr'], yerr=feat_lc_df['std_tr'], label='Training set')\n",
    "plt.errorbar(feat_lc_df.index+1, feat_lc_df['perf_te'], yerr=feat_lc_df['std_te'], label='Test set')\n",
    "plt.xticks(np.arange(1, 22, 1)) \n",
    "plt.xlabel('Number of features')\n",
    "plt.ylabel(sklearn_metric.__name__)\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the, with 5 features, it is about as good as it gets, given the error bars.\n",
    "\n",
    "We can then investigate all pairs of features among the top 5 to see which pair is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_perf = -1\n",
    "std_perf = -1\n",
    "best_i = 0\n",
    "best_j = 0\n",
    "for i in np.arange(5): \n",
    "    for j in np.arange(i+1,5): \n",
    "        df = data_df[[ranked_columns[i], ranked_columns[j], 'fruit']]\n",
    "        p_tr, s_tr, p_te, s_te = df_cross_validate(df, sklearn_model, sklearn_metric)\n",
    "        if p_te > best_perf: \n",
    "            best_perf = p_te\n",
    "            std_perf = s_te\n",
    "            best_i = i\n",
    "            best_j = i\n",
    "            \n",
    "metric_name = sklearn_metric.__name__.upper()\n",
    "print('BEST PAIR: {}, {}'.format(best_i, best_j))\n",
    "print(\"AVERAGE TEST {0:s} +- STD: {1:.2f} +- {2:.2f}\".format(metric_name, p_te, s_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-437b6a2bbd456104",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Not too surprisingly the first two features are best. We can also run a different kind of feature selection, but the results are very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8bb70b6720747f11",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# From https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "# 1.13.4.2. Tree-based feature selection\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "X = data_df.iloc[:, :-1].to_numpy()\n",
    "Y = data_df.iloc[:, -1].to_numpy()\n",
    "clf = ExtraTreesClassifier(n_estimators=50)\n",
    "clf = clf.fit(X, Y)\n",
    "ranked_columns = data_df.columns[np.argsort(-clf.feature_importances_)]\n",
    "print(ranked_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4a51f2f9f8140386",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exploring the metadata\n",
    "For those of you who will chose the project on how to find and correct bias in data, part of your work will be to analyze the metadata: can you predict for example \"apple\" vs. \"banana\" based on the meta-features? This would indicate some confounding factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c203a62825a8c375",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(os.path.join(data_dir, 'metadata.csv')) #, index_col='Num')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7dea2a096bf3283a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Select images with a single apple or banana\n",
    "is_apple  = metadata['Fruit'] == 'APPLE'\n",
    "is_banana = metadata['Fruit'] == 'BANANA'\n",
    "count_one = metadata['Count'] == '1-ONE'\n",
    "apple_subset = metadata[is_apple & count_one]\n",
    "banana_subset = metadata[is_banana & count_one]\n",
    "print('Apples: {}'.format(apple_subset.shape))\n",
    "print('Bananas: {}'.format(banana_subset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-db923f05b9b0b2c4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Only two variables are numerical, the others would have to be converted.\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html may not be the best solution\n",
    "# Read also https://www.kaggle.com/c/titanic/discussion/5379\n",
    "# See also https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder\n",
    "\n",
    "metadata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62d12aa081d9da1c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "series = ['Num', 'GPSAltitude', 'SubsecTimeDigitized']\n",
    "metadata_subset = apple_subset.copy()[series]\n",
    "metadata_subset = metadata_subset.append(banana_subset.copy()[series])\n",
    "na = len(apple_subset)\n",
    "nb = len(banana_subset)\n",
    "Y = np.append(np.ones([na, 1]), -1*np.ones([nb, 1]))\n",
    "metadata_subset['fruit'] = Y\n",
    "print(df.shape)\n",
    "metadata_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-be4288d944689f5d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Rappel de la question 2.1\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score as sklearn_metric\n",
    "sklearn_model = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6b0bbdf029c18994",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "naval = check_na(metadata_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc1052e381375de6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "metadata_subset[metadata_subset.isna()]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4fe6442a58d4581c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#metadata_subset.GPSAltitude[895]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-69966b92ba5b9b10",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "check_na(metadata_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c6e47a9938ac04a5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "p_tr, s_tr, p_te, s_te = df_cross_validate(metadata_subset, sklearn_model, sklearn_metric, n=10, verbose=False)\n",
    "metric_name = sklearn_metric.__name__.upper()\n",
    "print(\"AVERAGE TRAINING {0:s} +- STD: {1:.2f} +- {2:.2f}\".format(metric_name, p_tr, s_tr))\n",
    "print(\"AVERAGE TEST {0:s} +- STD: {1:.2f} +- {2:.2f}\".format(metric_name, p_te, s_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3fa808632a17d350",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "corr = metadata_subset.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e38efefb1b806626",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-64f1e5bf901068eb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Rather than doing feature selection, another avenue is to use feature transforms to reduce dimensionality, typically find the \"principal directions\"(directions of largest variance). This is achieved with SVD (the same algorithm we used last week to find the aspect ratio of an elongated object). There again I used my search engine and typed the keywords \"pandas svd\". I found a nice tutorial on [this page](https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/) and a step-by-step procedure on [this page](https://cmdlinetips.com/2019/05/singular-value-decomposition-svd-in-python/). Can you transform the original data frame into a data frame with only 2 features (the two first principal directions)?\n",
    "\n",
    "<u>Question 1:</u> Create a dataframe called `df_scaled` containing the standardized columns, except the last one (tip: use `drop` to eliminate the last column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-dedff9b2eb6eb74a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "df = pd.read_csv(os.path.join(data_dir, 'CS_data.csv'))\n",
    "df_bare = df.drop(columns=['fruit'])\n",
    "df_scaled = (df_bare-df_bare.mean())/df_bare.std()\n",
    "df_scaled.head()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-90fc1372ac1320ef",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<u>Question 2:</u> Perform a singular value decomposition of `df_scaled` and call the resulting matrices u, s, v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6c2ca3f2fb76d02e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "u, s, v = np.linalg.svd(df_scaled, full_matrices=True)\n",
    "print('U {}'.format(u.shape))\n",
    "print('S {}'.format(s.shape))\n",
    "print('V {}'.format(v.shape))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e9b912736689d530",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<u>Question 3:</u> Make a scree plot of the eigen values (square of the singular values). Save the plot in file 'svd_scree_plot.png'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a695af3051ad5a67",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "var_explained = np.round(s**2/np.sum(s**2), decimals=3)\n",
    "sns.barplot(x=list(range(1,len(var_explained)+1)),\n",
    "            y=var_explained, color=\"limegreen\")\n",
    "plt.xlabel('SVs', fontsize=16)\n",
    "plt.ylabel('Percent Variance Explained', fontsize=16)\n",
    "plt.savefig('svd_scree_plot.png',dpi=100)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88046105b30a3968",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<u>Question 4:</u> Create a new dataframe `svd_df` with the two singular values as columns and the fruit type as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-85c99285331bf2f7",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "labels= ['SV'+str(i) for i in range(1,4)]\n",
    "fruit_name = ['Banana', 'Apple']\n",
    "fruit_list = [fruit_name[int((i+1)/2)] for i in df[\"fruit\"].tolist()]\n",
    "svd_df = pd.DataFrame(u[:,0:3], columns=labels)\n",
    "svd_df['fruit'] = fruit_list\n",
    "svd_df.head()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-614ac8d15dd7ca81",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<u>Question 5:</u> Make pairwise scatter plots of the three first singular values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c33cf38618ace17d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "g = sns.pairplot(svd_df, hue=\"fruit\", markers=[\"o\", \"s\"], diag_kind=\"hist\")\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c02318f6b526e4ee",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<u>Question 6:</u> Compute the performances obtained with the 3 nearest neighbor method using the first 3 singular values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-11f5a7b6574936ce",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "svd_df['fruit'] = df.iloc[:, -1].to_numpy()\n",
    "p_tr, s_tr, p_te, s_te = df_cross_validate(svd_df, sklearn_model, sklearn_metric)\n",
    "metric_name = sklearn_metric.__name__.upper()\n",
    "print(\"AVERAGE TRAINING {0:s} +- STD: {1:.2f} +- {2:.2f}\".format(metric_name, p_tr, s_tr))\n",
    "print(\"AVERAGE TEST {0:s} +- STD: {1:.2f} +- {2:.2f}\".format(metric_name, p_te, s_te))\n",
    "### END SOLUTION"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "516px",
    "width": "321.667px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "211.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
